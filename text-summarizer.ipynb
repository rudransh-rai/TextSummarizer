{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport nltk\nimport heapq\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\n\n# Download necessary data for text processing\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Function to clean and preprocess the text\ndef preprocess_text(text):\n    \"\"\"\n    Preprocesses the input text by converting it to lowercase, removing special characters,\n    numbers, and stopwords, and then tokenizing it into words.\n    \"\"\"\n    # Convert text to lowercase\n    text = text.lower()\n\n    # Remove numbers in brackets and extra spaces\n    text = re.sub(r'\\[[0-9]*\\]', ' ', text)  # Example: [12]\n    text = re.sub(r'\\s+', ' ', text)\n\n    # Remove special characters and keep only letters\n    text = re.sub(r'[^a-zA-Z]', ' ', text)\n\n    # Tokenize the text into words\n    words = word_tokenize(text)\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    filtered_words = [word for word in words if word not in stop_words]\n\n    return filtered_words\n\n# Function to compute word frequency\ndef compute_word_frequencies(words):\n    \"\"\"\n    Computes the frequency of each word in the list and normalizes the frequencies.\n    \"\"\"\n    word_frequencies = {}\n\n    # Count the occurrences of each word\n    for word in words:\n        if word not in word_frequencies:\n            word_frequencies[word] = 1\n        else:\n            word_frequencies[word] += 1\n\n    # Normalize the frequencies by dividing by the maximum frequency\n    max_frequency = max(word_frequencies.values())\n    for word in word_frequencies:\n        word_frequencies[word] /= max_frequency\n\n    return word_frequencies\n\n# Function to score sentences based on word frequency\ndef score_sentences(text, word_frequencies):\n    \"\"\"\n    Scores each sentence based on the frequency of words it contains,\n    normalized by the length of the sentence.\n    \"\"\"\n    sentences = sent_tokenize(text)  # Tokenize text into sentences\n    sentence_scores = {}\n\n    for sentence in sentences:\n        sentence_word_count = len(sentence.split(' '))  # Count words in the sentence\n        for word in word_tokenize(sentence.lower()):\n            if word in word_frequencies:\n                if sentence not in sentence_scores:\n                    sentence_scores[sentence] = word_frequencies[word]\n                else:\n                    sentence_scores[sentence] += word_frequencies[word]\n\n        # Normalize sentence score by sentence length\n        sentence_scores[sentence] /= sentence_word_count\n\n    return sentence_scores\n\n# Function to summarize text\ndef summarize_text(text, num_sentences=3):\n    \"\"\"\n    Summarizes the given text by selecting the top sentences based on their scores.\n    \"\"\"\n    # Step 1: Preprocess the text\n    words = preprocess_text(text)\n\n    # Step 2: Compute word frequencies\n    word_frequencies = compute_word_frequencies(words)\n\n    # Step 3: Score sentences\n    sentence_scores = score_sentences(text, word_frequencies)\n\n    # Step 4: Select the top sentences for the summary\n    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n    summary = ' '.join(summary_sentences)\n\n    return summary\n\n# Sample text for summarization\ntext = \"\"\"The Threats of Artificial Intelligence\nArtificial Intelligence (AI) is one of the most revolutionary advancements in technology, with the potential to transform industries, enhance human capabilities, and address pressing global challenges. However, as we progress into an AI-driven era, it’s crucial to examine the significant threats and risks associated with its widespread adoption.\n\n1. Job Displacement and Economic Disruption\nAI's ability to automate tasks has already begun reshaping the job market. While it can lead to increased efficiency, many industries face the risk of massive job displacement. Tasks once requiring human skill, such as manufacturing, data entry, or even customer service, are now being handled by AI systems. This could widen the gap between skilled and unskilled workers, leading to economic inequality.\n\n2. Ethical Concerns and Bias\nAI algorithms are only as unbiased as the data they are trained on. If training data contains biases—whether racial, gender-based, or otherwise—AI systems will perpetuate and even amplify these biases. For example, AI in hiring systems or judicial sentencing could lead to unfair treatment of certain groups, raising serious ethical concerns.\n\n3. Privacy and Surveillance\nAI-powered tools like facial recognition and data analysis are increasingly used for surveillance, often without public consent. Governments and corporations can exploit these tools to monitor citizens, eroding privacy rights. In authoritarian regimes, AI-enhanced surveillance could stifle dissent and suppress freedoms.\n\n4. Autonomous Weapons and Warfare\nAI's potential for military applications poses grave risks. Autonomous weapons, or \"killer robots,\" could conduct warfare with minimal human oversight, leading to unintended escalations and civilian casualties. Moreover, the proliferation of such technology could fall into the hands of non-state actors or rogue states, heightening global security threats.\n\n5. Misinformation and Deepfakes\nAI-generated content, including deepfakes, can be used to spread misinformation on an unprecedented scale. From altering political speeches to creating convincing but fake videos, AI tools have the potential to manipulate public opinion, disrupt elections, and erode trust in media institutions.\n\n6. Lack of Accountability\nAs AI systems become more complex, understanding their decision-making processes becomes increasingly challenging. This \"black box\" problem makes it difficult to hold AI developers or users accountable for harmful outcomes. For instance, if an autonomous car causes an accident, determining responsibility can become a legal and ethical quagmire.\n\n7. Over-Reliance on AI\nDependence on AI systems can lead to vulnerabilities. In critical industries like healthcare, finance, or defense, over-reliance on AI could result in catastrophic consequences if these systems fail, are hacked, or produce erroneous outputs.\n\n8. Existential Risk\nProminent thinkers like Elon Musk and Stephen Hawking have warned about the existential risks of AI. Superintelligent systems, if not aligned with human values, could act in ways detrimental to humanity. While this remains speculative, the potential for AI to surpass human control cannot be ignored.\n\nAddressing the Threats\nWhile the threats posed by AI are significant, they are not insurmountable. Policymakers, technologists, and ethicists must work together to create robust regulations, ethical guidelines, and technological safeguards. This includes:\n\nEnsuring transparency and fairness in AI algorithms.\nEstablishing global treaties to prevent misuse of AI in warfare.\nPromoting public awareness and education about AI risks and benefits.\nEncouraging responsible AI development aligned with societal values.\nConclusion\nAI is a powerful tool that promises immense benefits, but its threats are equally significant. The future of AI depends on our ability to navigate its risks responsibly and ensure that it serves humanity’s best interests. By fostering a collaborative approach, we can harness AI’s potential while safeguarding against its perils.\n\"\"\"\n\n# Generate a summary for the sample text\nsummary = summarize_text(text)\n\n# Display the summary\nprint(\"Original Text:\")\nprint(text)\nprint(\"\\nSummary:\")\nprint(summary)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T14:58:35.122990Z","iopub.execute_input":"2025-01-12T14:58:35.123600Z","iopub.status.idle":"2025-01-12T14:59:41.566546Z","shell.execute_reply.started":"2025-01-12T14:58:35.123532Z","shell.execute_reply":"2025-01-12T14:59:41.564506Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e9007d4c121b>\u001b[0m in \u001b[0;36m<cell line: 140>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m# Generate a summary for the sample text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m# Display the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-e9007d4c121b>\u001b[0m in \u001b[0;36msummarize_text\u001b[0;34m(text, num_sentences)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Step 3: Score sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0msentence_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_frequencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# Step 4: Select the top sentences for the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-e9007d4c121b>\u001b[0m in \u001b[0;36mscore_sentences\u001b[0;34m(text, word_frequencies)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Normalize sentence score by sentence length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0msentence_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0msentence_word_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentence_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '1.'"],"ename":"KeyError","evalue":"'1.'","output_type":"error"}],"execution_count":1}]}